{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f912765e-59a6-443e-a9a6-4b988ea5cffc",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0754abea-abff-4251-b838-af5e022a388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f90933-d982-476b-9982-1cfa44cddfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_data_path = \"/home/panza/Downloads/UCI HAR Dataset/UCI HAR Dataset/train/Inertial Signals/\"\n",
    "ytrain_data_path = \"/home/panza/Downloads/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt\"\n",
    "xtest_data_path = \"/home/panza/Downloads/UCI HAR Dataset/UCI HAR Dataset/test/Inertial Signals/\"\n",
    "ytest_data_path = \"/home/panza/Downloads/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt\"\n",
    "data_groups=[\"body_acc\", \"total_acc\", \"body_gyro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141b382-c4f0-4cff-93ab-069475d172b4",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "Creo que lo difícil de esto va a ser transformar el dataset de campañas en algo similar al dataset de HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9f80d9-4636-4972-a836-f546b571f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    \"\"\"load files\"\"\"\n",
    "    np_array = pd.read_csv(path,\n",
    "                          header=None,\n",
    "                          delim_whitespace=True)\\\n",
    "                 .values\n",
    "    # con .values, devuelvo un array, que es lo que voy a necesitar para trabajar\n",
    "    \n",
    "    return np_array\n",
    "\n",
    "\n",
    "def load_groups(path, groups=[\"main\"]):\n",
    "    \"\"\"Load all groups into a dictionary\n",
    "    if no_groups ---> sigle group named \"main\"\n",
    "    \"\"\"\n",
    "    no_groups = False\n",
    "    file_list = os.listdir(path)\n",
    "    df_dict = {}\n",
    "    if len(groups) == 1:\n",
    "        no_groups = True\n",
    "    \n",
    "    for group in groups:\n",
    "        array_list = []\n",
    "        for file in file_list:\n",
    "            if (group in file) or (no_groups):\n",
    "                print(file[:-4], \"loaded\")  # [:-4 para sacarle el .txt]\n",
    "                array_list.append(load_file(path + file))\n",
    "\n",
    "        df_dict[group] = np.dstack(array_list)\n",
    "        print(group, \"group loaded!\\n\")\n",
    "        \n",
    "    print(\"\\n\\nData Loaded!\\n\")\n",
    "    \n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def concat_groups(array_dict, axis=2):\n",
    "    \"\"\"Takes every array in the dict and concatenates them accross an axis\"\"\"\n",
    "    array_list = list(array_dict.values())\n",
    "    return np.concatenate(array_list, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09101530-13ff-44d8-ad5e-294c06297522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_acc_z_train loaded\n",
      "body_acc_x_train loaded\n",
      "body_acc_y_train loaded\n",
      "body_acc group loaded!\n",
      "\n",
      "total_acc_y_train loaded\n",
      "total_acc_z_train loaded\n",
      "total_acc_x_train loaded\n",
      "total_acc group loaded!\n",
      "\n",
      "body_gyro_x_train loaded\n",
      "body_gyro_y_train loaded\n",
      "body_gyro_z_train loaded\n",
      "body_gyro group loaded!\n",
      "\n",
      "\n",
      "\n",
      "Data Loaded!\n",
      "\n",
      "body_acc_z_test loaded\n",
      "body_acc_y_test loaded\n",
      "body_acc_x_test loaded\n",
      "body_acc group loaded!\n",
      "\n",
      "total_acc_x_test loaded\n",
      "total_acc_z_test loaded\n",
      "total_acc_y_test loaded\n",
      "total_acc group loaded!\n",
      "\n",
      "body_gyro_x_test loaded\n",
      "body_gyro_z_test loaded\n",
      "body_gyro_y_test loaded\n",
      "body_gyro group loaded!\n",
      "\n",
      "\n",
      "\n",
      "Data Loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_array_dict = load_groups(xtrain_data_path, data_groups)\n",
    "y_train_array = load_file(ytrain_data_path)\n",
    "\n",
    "X_test_array_dict = load_groups(xtest_data_path, data_groups)\n",
    "y_test_array = load_file(ytest_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f6adee-4108-45d1-939b-80e246773989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array_dict[\"body_acc\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b167b3c-2cbb-47f6-9212-a886534a7606",
   "metadata": {},
   "source": [
    "#### Hasta acá, tengo un NumPy array\n",
    "#### (7352, 128) significa que tengo 7352 windows de datos, y cada window tiene 128 observaciones\n",
    "#### (7352, 128, 3) significa lo mismo, pero en 3 dimensiones. 7352 windows, 128 obs por window, 3 dimensiones (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74412ab3-7872-4c31-9836-ce2002a6bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437b5c49-5cde-4a7b-9f10-3260d52782f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_array_dict[\"body_acc\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bf3be-d9d5-4363-a30c-2280b2592440",
   "metadata": {},
   "source": [
    "#### Para hacerlo coincidir con el libro, me armo una función que me concatene los 3 grupos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a0c365-dda3-45a4-b968-f3f7dbf89519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = concat_groups(X_train_array_dict)\n",
    "X_test_array = concat_groups(X_test_array_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b595cd-59ae-47c2-a3ca-4a1ca960b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (2947, 128, 9)\n",
      "(7352, 1) (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_array.shape, X_test_array.shape)\n",
    "print(y_train_array.shape, y_test_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082133a-1047-43ed-b54d-cb9458a7857d",
   "metadata": {},
   "source": [
    "## Balance of Activity Classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f5a146-0775-44eb-963a-954c6d7eed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "1    1226\n",
       "2    1073\n",
       "3     986\n",
       "4    1286\n",
       "5    1374\n",
       "6    1407\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train_array).groupby(0).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb4203-0050-488e-a917-2a2bd6f4dea1",
   "metadata": {},
   "source": [
    "### En este caso, están balanceadas. Pero en el caso de la soja, voy a tener que balancear el dataset. \n",
    "(Me voy a tener que armar un custom dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65817606-f436-4a1f-bcfe-f152030552dd",
   "metadata": {},
   "source": [
    "## Problem Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841b363-659b-4aa6-8f75-a71800208be8",
   "metadata": {},
   "source": [
    "Una verga el capitulo... puro relleno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8af6d-fbb6-4fda-a61a-59fb4424d493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-tmeseries",
   "language": "python",
   "name": "dl-tmeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
